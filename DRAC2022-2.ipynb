{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAC2022 Task1 Segmentation\n",
    "## Data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering and copying complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 设置图片和掩码的路径\n",
    "image_dir = './inputs/DRAC-Segmentation/1. Original Images/a. Training Set'\n",
    "mask_dir = './inputs/DRAC-Segmentation/2. Groundtruths/a. Training Set/2. Nonperfusion Areas'\n",
    "output_dir = './inputs/DRAC-Segmentation/1. Original Images/2. Training Set'\n",
    "\n",
    "# 确保输出目录存在\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 读取掩码文件名\n",
    "mask_files = glob(os.path.join(mask_dir, '*.png'))  # 假设掩码扩展名为.png\n",
    "mask_basenames = {os.path.splitext(os.path.basename(mask))[0] for mask in mask_files}\n",
    "\n",
    "# 遍历图片文件\n",
    "image_files = glob(os.path.join(image_dir, '*.png'))  # 假设图片扩展名为.png\n",
    "for image_path in image_files:\n",
    "    image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    \n",
    "    # 如果图片的基本名在掩码文件名集中，表示两者匹配\n",
    "    if image_basename in mask_basenames:\n",
    "        # 复制文件到输出目录\n",
    "        shutil.copy(image_path, os.path.join(output_dir, os.path.basename(image_path)))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(\"Filtering and copying complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:07<00:00, 14.02it/s]\n"
     ]
    }
   ],
   "source": [
    "img_size = 1024\n",
    "\n",
    "image_dir = './inputs/DRAC-Segmentation/1. Original Images/2. Training Set'\n",
    "mask_dir = './inputs/DRAC-Segmentation/2. Groundtruths/a. Training Set/2. Nonperfusion Areas'\n",
    "\n",
    "os.makedirs('./inputs/DRAC2022/2.NA/train/images', exist_ok=True)\n",
    "os.makedirs('./inputs/DRAC2022/2.NA/train/masks/0', exist_ok=True)\n",
    "\n",
    "image_paths = glob(os.path.join(image_dir, '*'))\n",
    "\n",
    "for imgpath in tqdm(image_paths):\n",
    "    img = cv2.imread(imgpath)\n",
    "\n",
    "    # 根据图像文件名找到对应的掩码文件\n",
    "    base_name = os.path.splitext(os.path.basename(imgpath))[0]\n",
    "    mask_path = glob(os.path.join(mask_dir, base_name + '.png'))  # 假设掩码文件名与图像文件名匹配\n",
    "\n",
    "    if mask_path:  # 确保找到了掩码文件\n",
    "        mask_path = mask_path[0]\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask_ = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) > 127  # 读取并二值化掩码文件，生成布尔矩阵\n",
    "        mask[mask_] = 1  # 将对应位置的零矩阵更新为1，表示掩码区域\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.tile(img[..., None], (1, 1, 3))\n",
    "        if img.shape[2] == 4:\n",
    "            img = img[..., :3]\n",
    "\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        mask = cv2.resize(mask, (img_size, img_size))\n",
    "\n",
    "        cv2.imwrite(os.path.join('inputs/DRAC2022/2.NA/train/images', os.path.basename(imgpath)), img)\n",
    "        cv2.imwrite(os.path.join('inputs/DRAC2022/2.NA/train/masks/0', base_name + '.png'), (mask * 255).astype('uint8'))\n",
    "    else:\n",
    "        print(f\"No matching mask found for {imgpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "name: DRAC2022/2.NA/train_NestedUNet_woDS\n",
      "epochs: 40\n",
      "batch_size: 1\n",
      "arch: NestedUNet\n",
      "deep_supervision: False\n",
      "input_channels: 3\n",
      "num_classes: 1\n",
      "input_w: 1024\n",
      "input_h: 1024\n",
      "loss: DiceLoss\n",
      "dataset: DRAC2022/2.NA/train\n",
      "img_ext: .png\n",
      "mask_ext: .png\n",
      "optimizer: Adam\n",
      "lr: 0.0001\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0001\n",
      "nesterov: False\n",
      "scheduler: MultiStepLR\n",
      "min_lr: 1e-09\n",
      "factor: 0.1\n",
      "patience: 2\n",
      "milestones: 25\n",
      "gamma: 0.1\n",
      "early_stopping: -1\n",
      "weights: models/DRAC2022/2.NA/train_NestedUNet_woDS/Dice_model_epoch_100_loss_0.5470_iou_0.3387.pth\n",
      "num_workers: 4\n",
      "--------------------\n",
      "=> creating model NestedUNet\n",
      "=> loaded weights from 'models/DRAC2022/2.NA/train_NestedUNet_woDS/Dice_model_epoch_100_loss_0.5470_iou_0.3387.pth'\n",
      "Epoch [0/40]\n",
      "  0%|                                                    | 0/84 [00:00<?, ?it/s]^C\n"
     ]
    }
   ],
   "source": [
    "# !python train.py --name DRAC2022/2.NA/train_NestedUNet_woDS --dataset DRAC2022/2.NA/train -b 1 --epochs 100 --optimizer Adam --lr 2e-5 --min_lr 1e-9\n",
    "!python train.py --name DRAC2022/2.NA/train_NestedUNet_woDS --dataset DRAC2022/2.NA/train -b 1 --optimizer Adam --epochs 100 --lr 1e-5 --min_lr 1e-9 --weights models/DRAC2022/2.NA/train_NestedUNet_woDS/Dice_model_epoch_300_loss_0.3840_dice_0.6161.pth\n",
    "# !python train.py --dataset dsb2018_96 --optimizer Adam --min_lr 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python val.py --name DRAC2022/1.IMA/train_NestedUNet_woDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:04<00:00, 15.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "img_size = 1024\n",
    "\n",
    "image_dir = './inputs/DRAC-Segmentation/1. Original Images/b. Testing Set'\n",
    "\n",
    "os.makedirs('./inputs/DRAC2022/2.NA/test/images', exist_ok=True)\n",
    "\n",
    "image_paths = glob(os.path.join(image_dir, '*'))\n",
    "\n",
    "for imgpath in tqdm(image_paths):\n",
    "    img = cv2.imread(imgpath)\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        img = np.tile(img[..., None], (1, 1, 3))\n",
    "    if img.shape[2] == 4:\n",
    "        img = img[..., :3]\n",
    "\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    cv2.imwrite(os.path.join('inputs/DRAC2022/2.NA/test/images', os.path.basename(imgpath)), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "arch: NestedUNet\n",
      "batch_size: 1\n",
      "dataset: DRAC2022/2.NA/train\n",
      "deep_supervision: False\n",
      "early_stopping: -1\n",
      "epochs: 100\n",
      "factor: 0.1\n",
      "gamma: 0.1\n",
      "img_ext: .png\n",
      "input_channels: 3\n",
      "input_h: 1024\n",
      "input_w: 1024\n",
      "loss: DiceLoss\n",
      "lr: 1e-05\n",
      "mask_ext: .png\n",
      "milestones: 100\n",
      "min_lr: 1e-09\n",
      "momentum: 0.9\n",
      "name: DRAC2022/2.NA/train_NestedUNet_woDS\n",
      "nesterov: False\n",
      "num_classes: 1\n",
      "num_workers: 4\n",
      "optimizer: Adam\n",
      "patience: 2\n",
      "scheduler: CosineAnnealingLR\n",
      "weight_decay: 0.0001\n",
      "weights: models/DRAC2022/2.NA/train_NestedUNet_woDS/Dice_model_epoch_100_loss_0.3374_dice_0.6634.pth\n",
      "--------------------\n",
      "=> creating model NestedUNet\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/zhouxvdong/pytorch-nested-unet/predict2.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"/data/zhouxvdong/pytorch-nested-unet/predict2.py\", line 61, in main\n",
      "    model.load_state_dict(torch.load('models/DRAC2022/2.NA/train_UNet_woDS/Dice_model_epoch_200_loss_0.3127_dice_0.6894.pth'))\n",
      "  File \"/home/zhouxvdong/.conda/envs/neunet/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 2153, in load_state_dict\n",
      "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
      "RuntimeError: Error(s) in loading state_dict for NestedUNet:\n",
      "\tMissing key(s) in state_dict: \"conv0_1.conv1.weight\", \"conv0_1.conv1.bias\", \"conv0_1.bn1.weight\", \"conv0_1.bn1.bias\", \"conv0_1.bn1.running_mean\", \"conv0_1.bn1.running_var\", \"conv0_1.conv2.weight\", \"conv0_1.conv2.bias\", \"conv0_1.bn2.weight\", \"conv0_1.bn2.bias\", \"conv0_1.bn2.running_mean\", \"conv0_1.bn2.running_var\", \"conv1_1.conv1.weight\", \"conv1_1.conv1.bias\", \"conv1_1.bn1.weight\", \"conv1_1.bn1.bias\", \"conv1_1.bn1.running_mean\", \"conv1_1.bn1.running_var\", \"conv1_1.conv2.weight\", \"conv1_1.conv2.bias\", \"conv1_1.bn2.weight\", \"conv1_1.bn2.bias\", \"conv1_1.bn2.running_mean\", \"conv1_1.bn2.running_var\", \"conv2_1.conv1.weight\", \"conv2_1.conv1.bias\", \"conv2_1.bn1.weight\", \"conv2_1.bn1.bias\", \"conv2_1.bn1.running_mean\", \"conv2_1.bn1.running_var\", \"conv2_1.conv2.weight\", \"conv2_1.conv2.bias\", \"conv2_1.bn2.weight\", \"conv2_1.bn2.bias\", \"conv2_1.bn2.running_mean\", \"conv2_1.bn2.running_var\", \"conv0_2.conv1.weight\", \"conv0_2.conv1.bias\", \"conv0_2.bn1.weight\", \"conv0_2.bn1.bias\", \"conv0_2.bn1.running_mean\", \"conv0_2.bn1.running_var\", \"conv0_2.conv2.weight\", \"conv0_2.conv2.bias\", \"conv0_2.bn2.weight\", \"conv0_2.bn2.bias\", \"conv0_2.bn2.running_mean\", \"conv0_2.bn2.running_var\", \"conv1_2.conv1.weight\", \"conv1_2.conv1.bias\", \"conv1_2.bn1.weight\", \"conv1_2.bn1.bias\", \"conv1_2.bn1.running_mean\", \"conv1_2.bn1.running_var\", \"conv1_2.conv2.weight\", \"conv1_2.conv2.bias\", \"conv1_2.bn2.weight\", \"conv1_2.bn2.bias\", \"conv1_2.bn2.running_mean\", \"conv1_2.bn2.running_var\", \"conv0_3.conv1.weight\", \"conv0_3.conv1.bias\", \"conv0_3.bn1.weight\", \"conv0_3.bn1.bias\", \"conv0_3.bn1.running_mean\", \"conv0_3.bn1.running_var\", \"conv0_3.conv2.weight\", \"conv0_3.conv2.bias\", \"conv0_3.bn2.weight\", \"conv0_3.bn2.bias\", \"conv0_3.bn2.running_mean\", \"conv0_3.bn2.running_var\". \n",
      "\tsize mismatch for conv2_2.conv1.weight: copying a param with shape torch.Size([128, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 3, 3]).\n",
      "\tsize mismatch for conv1_3.conv1.weight: copying a param with shape torch.Size([64, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 320, 3, 3]).\n",
      "\tsize mismatch for conv0_4.conv1.weight: copying a param with shape torch.Size([32, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 192, 3, 3]).\n"
     ]
    }
   ],
   "source": [
    "!python predict2.py --name DRAC2022/2.NA/train_UNet_woDS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
